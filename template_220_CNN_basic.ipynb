{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCEP3DUjiJFq"
   },
   "source": [
    "# 220. CNN Basic\n",
    "\n",
    "## Convolution\n",
    "\n",
    "<img src='conv_layer.gif' height=60% width=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v96JMtkoiJFr"
   },
   "source": [
    "<img src = \"convolution.JPG\" width = 500, align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVop0OTiiJFs"
   },
   "source": [
    "- <code>nn.Conv2d</code> 의 parameter 는 random 하게 초기화되고, 훈련 과정에서 학습됨.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H863EE28iJFs"
   },
   "source": [
    "- 간단한 계산 예시를 위해 kernel parameter 값을 임의로 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C9EonNciJFs"
   },
   "source": [
    "- sample image를 4x4 크기로 생성  \n",
    "\n",
    "- ``torch.nn`` 은 미니 배치(mini-batch)만 지원하므로, `nnConv2D` 는 `nSamples x nChannels x Height x Width` 의\n",
    "    4차원 Tensor를 입력으로 한다. 하나의 샘플만 있다면, `input.unsqueeze(0)` 을 사용해서 가짜 차원을 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avOdFJwaiJFs"
   },
   "source": [
    "- convolution 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE36xfF2iJFt"
   },
   "source": [
    "### Convolutional Layer 의 output size 계산\n",
    "\n",
    "<img src = \"padding.JPG\" width = 500, align = \"center\">\n",
    "\n",
    "$$ \\text{output width} = \\lfloor\\frac{W - F_w + 2P}{S_w} + 1\\rfloor  $$\n",
    "$$ \\text{output height} = \\lfloor\\frac{H - F_h + 2P}{S_h} + 1 \\rfloor$$\n",
    "$W - \\text{input width}$  \n",
    "$F_{w,h} - \\text{filter width/height}$  \n",
    "$S_{w,h} - \\text{stride width/height}$  \n",
    "$P - padding$\n",
    "\n",
    "`conv output size = (input size - filter size + 2 * padding size) / stride size + 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QulQGhywiJFt"
   },
   "source": [
    "- no padding 의 경우 output image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aq7ZJzygiJFt"
   },
   "source": [
    "- padding=1 인 경우의 output image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7uT4CCtiJFu"
   },
   "source": [
    "## Pooling\n",
    "\n",
    "- Max Pooling - <code>torch.nn.MaxPool2d</code>  \n",
    "- Average Pooling - <code>torch.nn.AvgPool2d</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8deBHA6iJFu"
   },
   "source": [
    "### Multiple Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQJBRbayiJFv"
   },
   "source": [
    "### Flatten\n",
    "\n",
    "- ``torch.flatten(x, 1)``"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
