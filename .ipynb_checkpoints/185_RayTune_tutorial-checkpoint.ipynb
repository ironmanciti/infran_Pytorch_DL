{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pqJpzIABwrk"
   },
   "source": [
    "\n",
    "Hyperparameter tuning with Ray Tune\n",
    "===================================\n",
    "\n",
    "- Hyper-parameter Tuning은 평균 모델과 매우 정확한 모델을 구분할 수 있습니다. 다른 학습률을 선택하거나 네트워크 계층 크기를 변경하는 것과 같은 간단한 작업이 모델 성능에 큰 영향을 줄 수 있습니다.\n",
    "\n",
    "- [Ray Tune](https://docs.ray.io/en/latest/tune.html)은 최적의 매개변수 조합을 찾는 데 도움이 되는 도구 입니다.\n",
    "분산 하이퍼파라미터 튜닝 및 최신 하이퍼파라미터 검색 알고리즘,  TensorBoard, 분산 교육을 지원 및 기타 분석 라이브러리를 포함하는 업계 표준 도구입니다.\n",
    "\n",
    "- 이 튜토리얼에서는 CIFAR10 이미지 분류기를 훈련하기 위해 Ray Tune을 PyTorch 교육 워크플로에 통합하는 방법을 보여줍니다. \n",
    "\n",
    "- 다음과 같은 약간의 수정만 추가하면 됩니다.\n",
    "\n",
    "1. 함수에서 데이터 로드 및 training을 래핑합니다.\n",
    "2. 일부 네트워크 매개변수를 configurable 하게 만들고,\n",
    "3. 체크포인트 추가(선택 사항)\n",
    "4. 모델 튜닝을 위한 검색 공간 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z0cqqicHDl2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 1.31.0 requires google-auth<2.0dev,>=1.25.0, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install -q ray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iN5rxEJGBwrn"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W4-p652Bwro"
   },
   "source": [
    "데이터 로더\n",
    "----------\n",
    "데이터 로더를 자체 함수로 래핑하고 전역 데이터 디렉토리를 전달합니다.\n",
    "이런 식으로 서로 다른 trial 간에 데이터 디렉토리를 공유할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "40hXeDCvBwrp"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ3jdscmBwrq"
   },
   "source": [
    "Configurable neural network\n",
    "---------------------------\n",
    "구성 가능한 매개변수만 조정할 수 있습니다. 이 예에서는 완전 연결 계층의 계층 크기를 지정할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1pqoOIOZBwrr"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcD6n6lrBwrs"
   },
   "source": [
    "The train function\n",
    "------------------\n",
    "이제 [PyTorch 문서](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)에서 예제에 대한 몇 가지 변경 사항을 도입하기 때문에 흥미로워집니다. \n",
    "\n",
    "훈련 스크립트를 ``train_cifar(config, checkpoint_dir=None, data_dir=None)`` 함수로 래핑합니다.\n",
    "\n",
    "짐작할 수 있듯이 ``config`` 매개변수는 우리가 훈련할 하이퍼파라미터를 받습니다. ``checkpoint_dir`` 매개변수는 체크포인트를 복원하는 데 사용됩니다. ``data_dir``은 데이터를 로드하고 저장할 디렉토리를 지정하므로 여러 run이 동일한 데이터 소스를 공유할 수 있습니다.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    net = Net(config[\"l1\"], config[\"l2\"])\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "옵티마이저의 learning rate 도 configure 할 수 있습니다.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "또한 훈련 데이터를 훈련 및 검증 subset으로 나눕니다. 따라서 우리는 데이터의 80%에 대해 훈련하고 나머지 20%에 대해 유효성 검사 손실을 계산합니다. 훈련 및 테스트 세트를 iterate하는 batch size 도 cofigure 할 수 있습니다.\n",
    "\n",
    "DataParallel로 (다중) GPU 지원 추가\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "이미지 분류는 GPU의 이점이 많습니다. 운 좋게도 Ray Tune에서 PyTorch의 추상화를 계속 사용할 수 있습니다. 따라서 여러 GPU에서 데이터 병렬 train을 지원하기 위해 모델을 ``nn.DataParallel``로 래핑할 수 있습니다.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "By using a ``device`` variable we make sure that training also works when we have\n",
    "no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,\n",
    "like this:\n",
    "\n",
    "``device`` 변수를 사용하여 사용 가능한 GPU가 없을 때도 훈련이 작동하는지 확인합니다. PyTorch는 데이터를 GPU 메모리에 명시적으로 보내도록 다음가 같이, 요구합니다.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "이제 이 코드는 CPU, 단일 GPU 및 여러 GPU에 대한 교육을 지원합니다. 특히 Ray는 fractional GPU도 지원하므로 테스트 간에 GPU를 공유할 수 있습니다. 모델은 여전히 GPU 메모리에 fit 합니다. 나중에 다시 다루겠습니다.\n",
    "\n",
    "Communicating with Ray Tune\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "가장 흥미로운 부분은 Ray Tune과의 커뮤니케이션입니다.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "\n",
    "여기에서 먼저 체크포인트를 저장한 다음 일부 메트릭을 Ray Tune에 다시 보고합니다. 특히, 검증 손실과 정확도를 Ray Tune으로 다시 보냅니다. Ray Tune은 이러한 측정항목들을 사용하여 어떤 하이퍼파라미터 구성이 최상의 결과를 가져오는지 결정합니다. 이러한 메트릭은 또한 해당 시도에 리소스 낭비를 방지하기 위해 성능이 좋지 않은 시도를 조기에 중지하는 데 사용할 수 있습니다.\n",
    "\n",
    "체크포인트 저장은 선택사항이지만 Population Based Training과 같은 고급 스케줄러를 사용하려면 필요합니다.\n",
    "\n",
    "또한 체크포인트를 저장하면 나중에 훈련된 모델을 로드하고 테스트 세트에서 검증할 수 있습니다.\n",
    "\n",
    "Full training function\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "전체 코드 예제는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_jTLP3B1Bwrs"
   },
   "outputs": [],
   "source": [
    "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
    "    net = Net(config[\"l1\"], config[\"l2\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data(data_dir)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_eJCXU_Bwrt"
   },
   "source": [
    "보시다시피, 대부분의 코드는 원래 예제에서 직접 수정되었습니다.\n",
    "\n",
    "Test set accuracy\n",
    "-----------------\n",
    "일반적으로 머신 러닝 모델의 성능은 모델 훈련에 사용되지 않은 데이터로 홀드아웃 테스트 세트에서 테스트됩니다. 우리는 또한 이것을 함수로 래핑합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xs0d8yHqBwru"
   },
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgUxs9s8Bwru"
   },
   "source": [
    "이 함수는 또한 ``device`` 매개변수를 기대하므로 GPU에서 테스트 세트 유효성 검사를 수행할 수 있습니다.\n",
    "\n",
    "Configuring the search space\n",
    "----------------------------\n",
    "마지막으로 Ray Tune의 검색 공간을 정의해야 합니다. 다음은 예입니다.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "    }\n",
    "\n",
    "\n",
    "``tune.sample_from()`` 함수를 사용하면 하이퍼파라미터를 얻기 위해 고유한 샘플 메서드를 정의할 수 있습니다. 이 예에서 ``l1`` 및 ``l2`` 매개변수는 4에서 256 사이의 2의 거듭제곱이어야 하므로 4, 8, 16, 32, 64, 128 또는 256입니다.\n",
    "``lr``(학습률)은 0.0001과 0.1 사이에서 균일하게 샘플링되어야 합니다. 마지막으로 배치 크기는 2, 4, 8, 16 중에서 선택할 수 있습니다.\n",
    "\n",
    "각 trial 에서 Ray Tune은 이제 이러한 검색 공간에서 매개변수 조합을 무작위로 샘플링합니다. 그런 다음 여러 모델을 병렬로 훈련하고 이 중에서 가장 성능이 좋은 모델을 찾습니다. 또한 성능이 좋지 않은 시도를 조기에 종료하는 ``ASHAScheduler``를 사용합니다.\n",
    "\n",
    "``train_cifar`` 함수를 ``functools.partial``로 래핑하여 상수 ``data_dir`` 매개변수를 설정합니다. 또한 Ray Tune에 각 trial 에 사용할 수 있는 리소스가 무엇인지 알릴 수 있습니다.\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "    gpus_per_trial = 2\n",
    "    # ...\n",
    "    result = tune.run(\n",
    "        partial(train_cifar, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        checkpoint_at_end=True)\n",
    "\n",
    "CPU 수를 지정하여 사용할 수 있습니다. 예를 들어, PyTorch ``DataLoader`` 인스턴스의 ``num_workers``를 늘릴 수 있습니다. 각 trial에서는 선택한 수의 GPU가 PyTorch에 사용 됩니다. 각 Trial 은 요청되지 않은 GPU 에 액세스 권한이 없으므로 동일한 리소스 세트를 사용하는 두 개의 시도에 대해 신경 쓸 필요가 없습니다.\n",
    "\n",
    "각 trial은 GPU 공유도 가능합니다. ``gpus_per_trial=0.5``와 같은 것이 완전히 유효합니다.\n",
    "모델이 여전히 GPU 메모리에 맞는지 확인하기만 하면 됩니다.\n",
    "\n",
    "모델을 훈련시킨 후 가장 성능이 좋은 모델을 찾고 체크포인트 파일에서 훈련된 네트워크를 로드합니다. 그런 다음 테스트 세트 정확도를 얻고 모든 것을 인쇄하여 보고합니다.\n",
    "\n",
    "전체 주요 기능은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIThFvViBwrv"
   },
   "outputs": [],
   "source": [
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    load_data(data_dir)\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train_cifar, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K_5EAcIBwrv"
   },
   "source": [
    "코드를 실행하면 예를 들어 출력은 다음과 같을 수 있습니다.\n",
    "\n",
    "::\n",
    "\n",
    "    Number of trials: 10 (10 TERMINATED)\n",
    "    +-----+------+------+-------------+--------------+---------+------------+--------------------+\n",
    "    | ... |   l1 |   l2 |          lr |   batch_size |    loss |   accuracy | training_iteration |\n",
    "    |-----+------+------+-------------+--------------+---------+------------+--------------------|\n",
    "    | ... |   64 |    4 | 0.00011629  |            2 | 1.87273 |     0.244  |                  2 |\n",
    "    | ... |   32 |   64 | 0.000339763 |            8 | 1.23603 |     0.567  |                  8 |\n",
    "    | ... |    8 |   16 | 0.00276249  |           16 | 1.1815  |     0.5836 |                 10 |\n",
    "    | ... |    4 |   64 | 0.000648721 |            4 | 1.31131 |     0.5224 |                  8 |\n",
    "    | ... |   32 |   16 | 0.000340753 |            8 | 1.26454 |     0.5444 |                  8 |\n",
    "    | ... |    8 |    4 | 0.000699775 |            8 | 1.99594 |     0.1983 |                  2 |\n",
    "    | ... |  256 |    8 | 0.0839654   |           16 | 2.3119  |     0.0993 |                  1 |\n",
    "    | ... |   16 |  128 | 0.0758154   |           16 | 2.33575 |     0.1327 |                  1 |\n",
    "    | ... |   16 |    8 | 0.0763312   |           16 | 2.31129 |     0.1042 |                  4 |\n",
    "    | ... |  128 |   16 | 0.000124903 |            4 | 2.26917 |     0.1945 |                  1 |\n",
    "    +-----+------+------+-------------+--------------+---------+------------+--------------------+\n",
    "\n",
    "\n",
    "    Best trial config: {'l1': 8, 'l2': 16, 'lr': 0.00276249, 'batch_size': 16, 'data_dir': '...'}\n",
    "    Best trial final validation loss: 1.181501\n",
    "    Best trial final validation accuracy: 0.5836\n",
    "    Best trial test set accuracy: 0.5806\n",
    "\n",
    "대부분의 시도는 자원 낭비를 피하기 위해 일찍 중단되었습니다.\n",
    "가장 잘 수행된 시험은 테스트 세트에서 확인할 수 있는 약 58%의 검증 정확도를 달성했습니다.\n",
    "\n",
    "이제 PyTorch 모델의 매개변수를 조정할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Noi1YNyxRJkX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hyperparameter_tuning_tutorial.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
