{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6G4QgWiDwNQ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5DY7857DwNV"
   },
   "source": [
    "# 125. Torchtext library를 이용한 Text Classification \n",
    "\n",
    "이 튜토리얼에서는 Torchtext 라이브러리를 사용하여 텍스트 분류 분석을 위한 데이터 세트를 구축하는 방법을 보여줍니다. 사용자는 유연하게\n",
    "\n",
    "    - iterator로 원시 데이터에 액세스\n",
    "    - 원시 텍스트 문자열을 모델 학습에 사용할 수 있는``torch.Tensor``로 변환하는 데이터 처리 파이프 라인 구축  \n",
    "    - `torch.utils.data.DataLoader`를 사용하여 데이터를 shuffle and iterate\n",
    "    \n",
    "- [EmbeddingBag Layer 를 이용한 simple classification](https://jamesmccaffrey.wordpress.com/2021/04/14/explaining-the-pytorch-enbeddingbag-layer/)\n",
    "\n",
    "<img src=\"regular_embedding_vs_embedding_bag_diagram.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3raPMnvDwNX"
   },
   "source": [
    "## iterator로 원시 데이터에 액세스\n",
    "\n",
    "torchtext library는 원시 텍스트 문자열을 생성하는 몇 가지 원시 데이터세트 iteratior를 제공합니다. 예를 들어,``AG_NEWS`` 데이터세트 iterator는 라벨과 텍스트의 튜플로 원시 데이터를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "YTj5oQMgDwNZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# from torchtext.datasets import AG_NEWS\n",
    "# train_iter = AG_NEWS(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5j-Ac688JoMN",
    "outputId": "aff9a9bb-f10b-4da8-843e-c620c2d6189c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 24.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "train_iter = IMDB(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da4BD8FIFXe7",
    "outputId": "44f35676-429e-45a9-bead-60a59bc623ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg',\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbGTt4BeFdJ3",
    "outputId": "a61813cc-049f-4398-eaa4-d2a7ae419684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg',\n",
       " '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYecM1R5DwNb"
   },
   "source": [
    "## 데이터 처리 파이프 라인 준비\n",
    "\n",
    "우리는 어휘, 단어 벡터, 토크나이저를 포함하여 토치 텍스트 라이브러리의 매우 기본적인 구성요소를 다시 방문했습니다. 이것들은 원시 텍스트 문자열에 대한 기본 데이터 처리 빌딩 블록입니다.\n",
    "\n",
    "다음은 토크나이저 및 어휘를 사용한 일반적인 NLP 데이터 처리의 예입니다. 첫 번째 단계는 원시 훈련 데이터 세트로 어휘를 구축하는 것입니다. 여기서는 \n",
    "토큰의 목록 또는 반복자를 생성하는 반복자를 허용하는 내장 팩토리 함수 `build_vocab_from_iterator`를 사용합니다. 사용자는 어휘에 추가할 특수 기호를 전달할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DTIosyBGDwNd"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# train_iter = AG_NEWS(split='train')\n",
    "\n",
    "train_iter = IMDB(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhX2H37zGNzC",
    "outputId": "ab3d5e29-637f-40ae-e734-6aef0c5d9039"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[131, 9, 40, 464]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFwu1-LTDwNg"
   },
   "source": [
    "토크나이저와 vocabulary로 텍스트 처리 파이프라인을 준비합니다. 텍스트 및 레이블 파이프라인은 데이터 세트 반복자의 원시 데이터 문자열을 처리하는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkeuD7VGD6uT",
    "outputId": "b5675545-ae0c-4042-cbb6-64650ab8658d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 30, 5297]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "S2SXoMmVDwNh"
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "# label_pipeline = lambda x: int(x) - 1                     #AG_NEWS 1~4\n",
    "\n",
    "label_pipeline = lambda x: 0 if x == 'neg' else 1      #IMDB 'neg', 'pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFWzCvw7DwNk"
   },
   "source": [
    "텍스트 파이프라인은 어휘에 정의된 조회 테이블을 기반으로 텍스트 문자열을 정수 목록으로 변환합니다. 레이블 파이프라인은 레이블을 정수로 변환합니다. 예를 들어,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QC3OdaKDGnrC",
    "outputId": "b2794d5d-bbc1-4be4-d802-b7e6cb2cb097"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[131, 9, 1, 40, 464]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXR8heMqGrgj",
    "outputId": "4977e571-f6bd-4ad7-b7b9-9335835f852b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline('10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAMmMRwNDwNk"
   },
   "source": [
    "## data batch 와 iterator 생성\n",
    "\n",
    "Pytorch 사용자들은 `torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`를 사용할 것을 권고합니다.\n",
    "(tutorial <https://pytorch.org/tutorials/beginner/data_loading_tutorial.html>).\n",
    "\n",
    "\n",
    "``getitem()`` 및 ``len()`` 프로토콜을 구현하는 map 스타일 데이터세트와 함께 작동하며 인덱스/키에서 데이터 샘플까지의 map을 나타냅니다. 또한 shuffle 인수가 ``False``인 iterable dataset에서도 작동합니다.\n",
    "\n",
    "\n",
    "모델로 보내기 전에 ``collate_fn`` 함수는 ``DataLoader``에서 생성된 샘플 배치에서 작동합니다. ``collate_fn``에 대한 입력은 ``DataLoader``의 배치 크기를 가진 데이터 배치이며, ``collate_fn``은 이전에 선언된 데이터 처리 파이프라인에 따라 처리합니다. 여기에서 ``collate_fn``이 최상위 def로 선언되었는지 확인하십시오. 이렇게 하면 각 worker에서 해당 기능을 사용할 수 있습니다.\n",
    "\n",
    "이 예에서 원본 데이터 일괄 입력의 텍스트 항목은 list로 압축되고 ``nn.EmbeddingBag`` 입력에 대한 단일 텐서로 연결됩니다. 오프셋은 텍스트 텐서에서 개별 시퀀스의 시작 인덱스를 나타내는 delimiter 텐서입니다. 레이블은 개별 텍스트 항목의 레이블을 저장하는 텐서입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fq9iR173DwNl"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)    \n",
    "\n",
    "# train_iter = AG_NEWS(split='train')\n",
    "\n",
    "train_iter = IMDB(split='train')\n",
    "\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV6qR0l2DwNn"
   },
   "source": [
    "## model 정의\n",
    "\n",
    "모델은`nn.EmbeddingBag` 레이어와 classification을 위한 linear layer로 구성됩니다. default 모드가 \"mean\"인``nn.EmbeddingBag``는 임베딩 \"bag\"의 평균 값을 계산합니다. 텍스트 entry는 각각 길이가 다르다 해도 nn.EmbeddingBag 모듈은 텍스트 길이가 오프셋으로 저장되므로 padding이 필요하지 않습니다.\n",
    "\n",
    "또한``nn.EmbeddingBag``는 즉시 임베딩에 걸쳐 평균을 누적하므로``nn.EmbeddingBag``는 일련의 텐서를 처리하기 위해 성능과 메모리 효율성을 향상시킬 수 있습니다.\n",
    "\n",
    "<img src=\"embedding_bag.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dtq3XKpADwNo"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyblBEq9DwNp"
   },
   "source": [
    "Initiate an instance\n",
    "--------------------\n",
    "\n",
    "AG_NEWS 데이터 세트에는 4 개의 레이블이 있으므로 클래스 수는 4 개입니다.\n",
    "```\n",
    "   1 : World  \n",
    "   2 : Sports  \n",
    "   3 : Business  \n",
    "   4 : Sci/Tec  \n",
    "   \n",
    "```\n",
    "IMDB 데이터 세트에는 2 개의 레이블('nge', 'pos')이 있으므로 클래스 수는 2 개입니다.\n",
    "   \n",
    "vocab size는 vocab 길이와 같습니다 (single word, ngram 단어 포함).  클래스 수는 레이블 수와 같습니다.  \n",
    "AG_NEWS의 경우 4입니다.\n",
    "\n",
    "임베딩 차원이 64 인 모델을 빌드합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sfDrwMibDwNp"
   },
   "outputs": [],
   "source": [
    "# train_iter = AG_NEWS(split='train')\n",
    "\n",
    "train_iter =IMDB(split='train')\n",
    "\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKoZ69juKwvh",
    "outputId": "a55b1c5e-908e-4fb3-b5cc-5fff8341897b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiP8-Gl2DwNp"
   },
   "source": [
    "모델을 훈련시키고 결과를 평가하는 함수를 정의합니다.\n",
    "---------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9DwOqfeoDwNq"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk8VBVCdDwNq"
   },
   "source": [
    "데이터 세트 분할 및 모델 실행\n",
    "-----------------------------------\n",
    "\n",
    "원래``AG_NEWS``에는 유효한 데이터세트가 없으므로 훈련 데이터세트를 0.95 (train) 및 0.05 (valid)의 분할 비율로 train/valid 세트로 분할합니다. Pytorch core library 함수(`torch.utils.data.dataset.random_split`)를 사용합니다.\n",
    "\n",
    "\n",
    "`CrossEntropyLoss` criterion 은 `nn.LogSoftmax() + nn.NLLLoss()` 입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr5TbQ-mDwNq",
    "outputId": "feb730ab-9332-4278-becc-96e6215cc25b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 10.58s | valid accuracy    0.728 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 10.70s | valid accuracy    0.802 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 10.84s | valid accuracy    0.838 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 10.93s | valid accuracy    0.842 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 11.03s | valid accuracy    0.857 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 10.95s | valid accuracy    0.859 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 10.66s | valid accuracy    0.844 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 10.93s | valid accuracy    0.875 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 11.09s | valid accuracy    0.878 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 10.80s | valid accuracy    0.874 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "  \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "# train_iter, test_iter = AG_NEWS()\n",
    "\n",
    "train_iter, test_iter  =IMDB()\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyqWGP7uDwNr"
   },
   "source": [
    "Evaluate the model with test dataset\n",
    "------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gqiKYkTDwNr"
   },
   "source": [
    "Checking the results of the test dataset…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AP3hbUn-DwNs",
    "outputId": "48436292-6182-4a45-8653-c9c26c89e686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.867\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnE6XRK1DwNt"
   },
   "source": [
    "무작위 뉴스에서 테스트\n",
    "---------------------\n",
    "\n",
    "지금까지 best 모델을 사용하고 골프 뉴스를 테스트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23_D-WhADwNt",
    "outputId": "66315bb3-a69d-4120-bdbc-30dc9ce5edcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sports news\n"
     ]
    }
   ],
   "source": [
    "# ag_news_label = {1: \"World\",\n",
    "#                  2: \"Sports\",\n",
    "#                  3: \"Business\",\n",
    "#                  4: \"Sci/Tec\"}\n",
    "\n",
    "# def predict(text, text_pipeline):\n",
    "#     with torch.no_grad():\n",
    "#         text = torch.tensor(text_pipeline(text))\n",
    "#         output = model(text, torch.tensor([0]))\n",
    "#         return output.argmax(1).item() + 1\n",
    "\n",
    "# ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "#     enduring the season’s worst weather conditions on Sunday at The \\\n",
    "#     Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "#     considering the wind and the rain was a respectable showing. \\\n",
    "#     Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "#     was another story. With temperatures in the mid-80s and hardly any \\\n",
    "#     wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "#     Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "#     finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "#     was even more impressive considering he’d never played the \\\n",
    "#     front nine at TPC Southwind.\"\n",
    "\n",
    "# model = model.to(\"cpu\")\n",
    "\n",
    "# print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tk0_16TnJCEZ",
    "outputId": "53cea3ff-ee01-49f7-81ac-536941cc380e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()\n",
    "\n",
    "# negative test review\n",
    "# example = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n",
    "# positive test review\n",
    "example= 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "predicted = predict(example, text_pipeline)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzFYf3qmLJ0s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_sentiment_ngrams_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
