{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUOrHll26NTA"
   },
   "source": [
    "# 320. Basic LSTM 이해\n",
    "\n",
    "\n",
    "## Define the LSTM\n",
    "\n",
    "- `nn.LSTM`을 사용하여 RNN 레이어를 생성한 다음, 원하는 출력 크기를 얻기 위해 fully-connected layer를 추가  \n",
    "\n",
    "\n",
    "- torch.nn.RNN 의 parameters:  \n",
    "\n",
    "    * **input_size** - input 의 feature 수\n",
    "    * **hidden_size** - RNN 출력 및 hidden state의 feature 수\n",
    "    * **num_layers** - RNN stacked 레이어 수. **Default: 1**\n",
    "    * **batch_first** - True: input and output tensors 의 shape=(batch, seq, feature). **Default: False**\n",
    "    * **bidirectional** – True:  bidirectional RNN. **Default: False**   \n",
    "    \n",
    "    \n",
    "- Inputs: input,  (h_0, c_0)\n",
    "\n",
    "    - input shape - (seq_len, batch, input_size)\n",
    "    - h_0 shape - (num_layers * num_directions, batch, hidden_size). **Default: 0**\n",
    "    - c_0 shape - (num_layers * num_directions, batch, hidden_size)\n",
    "    \n",
    "    \n",
    "- Outputs: output, output, (h_n, c_n)\n",
    "    - output - (seq_len, batch, num_directions * hidden_size)  \n",
    "    - h_n - (num_layers * num_directions, batch, hidden_size)\n",
    "    - c_n - (num_layers * num_directions, batch, hidden_size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple LSTM 생성하여 LSTM의 특성 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(5, 16, batch_first=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 5\n",
    "hidden_dim = 16\n",
    "n_layers = 1\n",
    "\n",
    "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "lstm_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple LSTM을 test 하기 위해 toy data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input =  tensor([[[-2.0740, -1.7335, -1.0397, -0.1400,  0.4212]],\n",
      "\n",
      "        [[-0.4526,  1.0128, -1.5894, -0.4716, -1.4122]],\n",
      "\n",
      "        [[ 0.2714,  0.8112, -0.3092, -0.3101,  0.9504]],\n",
      "\n",
      "        [[-1.2765, -0.7081, -0.8103, -0.0700,  0.3390]],\n",
      "\n",
      "        [[-1.2912,  0.6906,  1.4694,  1.2355,  2.2444]]])\n",
      "input shape =  torch.Size([5, 1, 5])\n",
      "\n",
      "hidden shape =  torch.Size([1, 5, 16]) torch.Size([1, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "seq_len = 1\n",
    "\n",
    "#input\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "\n",
    "print(\"input = \", inp)\n",
    "print(\"input shape = \", inp.shape)\n",
    "print()\n",
    "\n",
    "#hidden state\n",
    "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "\n",
    "hidden = (hidden_state, cell_state)\n",
    "\n",
    "print(\"hidden shape = \", hidden_state.shape, cell_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에서 생성한 toy data 를 lstm_layer 에 입력하여 출력 및 new hidden state 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM output shape (seq, batch, hidden):  torch.Size([5, 1, 16])\n",
      "h_n (num_layers, batch, hidden):  torch.Size([1, 5, 16])\n",
      "c_n (num_layers, batch, hidden):  torch.Size([1, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "out, hidden = lstm_layer(inp, hidden)\n",
    "\n",
    "print(\"LSTM output shape (seq, batch, hidden): \", out.shape)\n",
    "print(\"h_n (num_layers, batch, hidden): \", hidden[0].shape)\n",
    "print(\"c_n (num_layers, batch, hidden): \", hidden[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-Many, Many-to-One Type 의 output 비교\n",
    "\n",
    "- LSTM 은 가변 길이의 sequence data 를 입력 받아 \n",
    "\n",
    "### Many-to-Many \n",
    "    - 각 sequence 의 output 모두 사용\n",
    "    \n",
    "### Many-to-One\n",
    "    - last output 만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-Many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 5])\n",
      "torch.Size([5, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "seq_len = 3\n",
    "\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "out, hidden = lstm_layer(inp, hidden)\n",
    "\n",
    "print(inp.shape)\n",
    "print(out.shape)  # many-to-many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16])\n"
     ]
    }
   ],
   "source": [
    "#last output (many-to-one) 만 출력\n",
    "out = out[:, -1]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연속된 5 개의 숫자를 보고 다음 숫자를 알아맞추도록 LSTM 을 이용한 model 작성\n",
    "\n",
    "- data 는 0 ~ 99 까지의 연속된 5개의 숫자 sequence 이고, target 은 (5 ~ 105) * 2 로 구성한다.   \n",
    "- 입력  sequence 에 대응하는 target을 예측하는 model 을 LSTM 으로 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "ddNibtIk6NTE",
    "outputId": "9de16996-77ce-4c5b-8f71-f6249fb0a519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5], [6], [7], [8], [9]]\n",
      "[20]\n"
     ]
    }
   ],
   "source": [
    "Numbers = [[i] for i in range(105)]\n",
    "\n",
    "Data = []\n",
    "Target = []\n",
    "for i in range(5, len(Numbers)):\n",
    "    Data.append(Numbers[i-5: i])\n",
    "    Target.append([Numbers[i][0] * 2])\n",
    "\n",
    "print(Data[5])\n",
    "print(Target[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 5, 1]), torch.Size([100, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(Data, dtype=torch.float) / 100   #scaling\n",
    "Y = torch.tensor(Target, dtype=torch.float) / 100\n",
    "X.size(), Y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "ds = TensorDataset(X, Y)\n",
    "ds_loader = DataLoader(ds, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.shape[0]\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = out.reshape(batch_size, -1, self.hidden_dim)  #batch first\n",
    "        output = self.fc(out)\n",
    "        return output[:, -1], hidden      #many-to-one\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).detach()\n",
    "        # same type, device, filled with zeros\n",
    "        h0 = weight.new_zeros(self.n_layers, batch_size, self.hidden_dim) \n",
    "        c0 = weight.new_zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return (h0, c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(1, 16, 1, 1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 5\n",
    "\n",
    "for step in range(epochs):   \n",
    "\n",
    "    for x, y in ds_loader:\n",
    "        # hidden state 초기화\n",
    "        h = model.init_hidden(batch_size) \n",
    "        \n",
    "        prediction, hidden = model(x, h)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(prediction, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = X.shape[0]\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "y_pred, hidden = model(X, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted value')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y.numpy(), y_pred.detach().numpy(), marker='.')\n",
    "plt.xlabel('True value')\n",
    "plt.ylabel('Predicted value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mYEp5Cn6NTW"
   },
   "source": [
    "- 임의의 연속된 숫자와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RUmHGYCW6NTy",
    "outputId": "5189462a-77e6-4db7-e3d7-231636b9a774"
   },
   "outputs": [],
   "source": [
    "test_data = torch.tensor([[35], [36], [37], [38], [39]], dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "x = test_data / 100\n",
    "h = model.init_hidden(1)\n",
    "\n",
    "prediction, hidden = model(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.28691506385803"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "99-1. Simple LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
