{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습\n",
    "\n",
    "### UCI Machine Learning Repository 의 Auto MPG dataset 을 사용하여 Regression 예측 model 작성\n",
    "\n",
    "auto-mpg.data - data file  \n",
    "auto-mpg.names - data 설명 file\n",
    "\n",
    "1. mpg:           continuous  \n",
    "2. cylinders:     multi-valued discrete  \n",
    "3. displacement:  continuous (배기량)   \n",
    "4. horsepower:    continuous  \n",
    "5. weight:        continuous  \n",
    "6. acceleration:  continuous  \n",
    "7. model year:    multi-valued discrete  \n",
    "8. origin:        multi-valued discrete, 1 - USA, 2 - Europe, 3 - Japan  \n",
    "9. car name:      string (unique for each instance)  \n",
    "\n",
    "Missing Attribute Values:  horsepower has 6 missing values  ==> \"?\" 로 들어 있으므로 read_csv 시 nan 으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load 및 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "file_name = \"auto-mpg.data\"\n",
    "\n",
    "with open(file_name, \"wb\") as file:\n",
    "    response = get(url)\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model year  origin  \n",
       "0          70       1  \n",
       "1          70       1  \n",
       "2          70       1  \n",
       "3          70       1  \n",
       "4          70       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin']\n",
    "\n",
    "rawdata = pd.read_csv(file_name, names=column_names, na_values=\"?\", comment=\"\\t\", sep=\" \", skipinitialspace=True)\n",
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.dropna(inplace=True)\n",
    "\n",
    "data = rawdata.copy()\n",
    "\n",
    "data = pd.get_dummies(data, columns=['cylinders', 'origin'])\n",
    "\n",
    "label = data.pop('mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 13) (98, 13) (294,) (98,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.values, label.values, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ts = torch.FloatTensor(X_train)\n",
    "X_test_ts = torch.FloatTensor(X_test)\n",
    "y_train_ts = torch.FloatTensor(y_train).view(-1, 1)\n",
    "y_test_ts = torch.FloatTensor(y_test).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearReg, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = self.fc3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearReg(X_train.shape[1], 1).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(X_train_ts, y_train_ts)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 522.6287\n",
      "epoch 2 loss: 422.1789\n",
      "epoch 3 loss: 414.5392\n",
      "epoch 4 loss: 869.1130\n",
      "epoch 5 loss: 343.9798\n",
      "epoch 6 loss: 434.5623\n",
      "epoch 7 loss: 288.2642\n",
      "epoch 8 loss: 149.7850\n",
      "epoch 9 loss: 165.6531\n",
      "epoch 10 loss: 247.6780\n",
      "epoch 11 loss: 107.8704\n",
      "epoch 12 loss: 133.6342\n",
      "epoch 13 loss: 17.5251\n",
      "epoch 14 loss: 23.6408\n",
      "epoch 15 loss: 10.3796\n",
      "epoch 16 loss: 16.2692\n",
      "epoch 17 loss: 24.2909\n",
      "epoch 18 loss: 4.3552\n",
      "epoch 19 loss: 4.4538\n",
      "epoch 20 loss: 9.6650\n",
      "epoch 21 loss: 0.8357\n",
      "epoch 22 loss: 12.1340\n",
      "epoch 23 loss: 1.4772\n",
      "epoch 24 loss: 10.0165\n",
      "epoch 25 loss: 2.6570\n",
      "epoch 26 loss: 8.2697\n",
      "epoch 27 loss: 4.7101\n",
      "epoch 28 loss: 12.1285\n",
      "epoch 29 loss: 9.3521\n",
      "epoch 30 loss: 3.1757\n",
      "epoch 31 loss: 10.0989\n",
      "epoch 32 loss: 4.1685\n",
      "epoch 33 loss: 21.2172\n",
      "epoch 34 loss: 3.7533\n",
      "epoch 35 loss: 4.8498\n",
      "epoch 36 loss: 2.2384\n",
      "epoch 37 loss: 1.5958\n",
      "epoch 38 loss: 1.5697\n",
      "epoch 39 loss: 11.3034\n",
      "epoch 40 loss: 11.4147\n",
      "epoch 41 loss: 6.0330\n",
      "epoch 42 loss: 11.6454\n",
      "epoch 43 loss: 3.7285\n",
      "epoch 44 loss: 25.6524\n",
      "epoch 45 loss: 2.8625\n",
      "epoch 46 loss: 16.1988\n",
      "epoch 47 loss: 3.0934\n",
      "epoch 48 loss: 1.9524\n",
      "epoch 49 loss: 3.1005\n",
      "epoch 50 loss: 2.1306\n",
      "epoch 51 loss: 2.2010\n",
      "epoch 52 loss: 5.9407\n",
      "epoch 53 loss: 4.5782\n",
      "epoch 54 loss: 3.1484\n",
      "epoch 55 loss: 4.7281\n",
      "epoch 56 loss: 9.8763\n",
      "epoch 57 loss: 2.2237\n",
      "epoch 58 loss: 3.8972\n",
      "epoch 59 loss: 6.6000\n",
      "epoch 60 loss: 1.4645\n",
      "epoch 61 loss: 4.6403\n",
      "epoch 62 loss: 4.8032\n",
      "epoch 63 loss: 4.8393\n",
      "epoch 64 loss: 5.5106\n",
      "epoch 65 loss: 4.0508\n",
      "epoch 66 loss: 5.1746\n",
      "epoch 67 loss: 11.9766\n",
      "epoch 68 loss: 3.6276\n",
      "epoch 69 loss: 6.5171\n",
      "epoch 70 loss: 8.2104\n",
      "epoch 71 loss: 2.4896\n",
      "epoch 72 loss: 1.9717\n",
      "epoch 73 loss: 4.1318\n",
      "epoch 74 loss: 3.9110\n",
      "epoch 75 loss: 2.1120\n",
      "epoch 76 loss: 10.3311\n",
      "epoch 77 loss: 2.6977\n",
      "epoch 78 loss: 3.8785\n",
      "epoch 79 loss: 7.2212\n",
      "epoch 80 loss: 2.4292\n",
      "epoch 81 loss: 2.0886\n",
      "epoch 82 loss: 6.7702\n",
      "epoch 83 loss: 1.1197\n",
      "epoch 84 loss: 6.5608\n",
      "epoch 85 loss: 1.0363\n",
      "epoch 86 loss: 6.2801\n",
      "epoch 87 loss: 3.0404\n",
      "epoch 88 loss: 5.3786\n",
      "epoch 89 loss: 4.3107\n",
      "epoch 90 loss: 1.5206\n",
      "epoch 91 loss: 14.7376\n",
      "epoch 92 loss: 2.8286\n",
      "epoch 93 loss: 14.5715\n",
      "epoch 94 loss: 14.6872\n",
      "epoch 95 loss: 2.1772\n",
      "epoch 96 loss: 5.3644\n",
      "epoch 97 loss: 10.2725\n",
      "epoch 98 loss: 13.9701\n",
      "epoch 99 loss: 4.7218\n",
      "epoch 100 loss: 1.5643\n",
      "epoch 101 loss: 0.5921\n",
      "epoch 102 loss: 9.2886\n",
      "epoch 103 loss: 7.5923\n",
      "epoch 104 loss: 2.0203\n",
      "epoch 105 loss: 3.0576\n",
      "epoch 106 loss: 7.3931\n",
      "epoch 107 loss: 3.5305\n",
      "epoch 108 loss: 0.6249\n",
      "epoch 109 loss: 8.1618\n",
      "epoch 110 loss: 6.4176\n",
      "epoch 111 loss: 3.6714\n",
      "epoch 112 loss: 10.5680\n",
      "epoch 113 loss: 9.8402\n",
      "epoch 114 loss: 5.2027\n",
      "epoch 115 loss: 1.2570\n",
      "epoch 116 loss: 7.6294\n",
      "epoch 117 loss: 0.9639\n",
      "epoch 118 loss: 9.8661\n",
      "epoch 119 loss: 0.2754\n",
      "epoch 120 loss: 2.0399\n",
      "epoch 121 loss: 1.9999\n",
      "epoch 122 loss: 2.8354\n",
      "epoch 123 loss: 4.9017\n",
      "epoch 124 loss: 3.3027\n",
      "epoch 125 loss: 3.1634\n",
      "epoch 126 loss: 3.5047\n",
      "epoch 127 loss: 10.6651\n",
      "epoch 128 loss: 1.6212\n",
      "epoch 129 loss: 7.1094\n",
      "epoch 130 loss: 1.9812\n",
      "epoch 131 loss: 3.1454\n",
      "epoch 132 loss: 1.2463\n",
      "epoch 133 loss: 2.2564\n",
      "epoch 134 loss: 8.8123\n",
      "epoch 135 loss: 2.0001\n",
      "epoch 136 loss: 6.1810\n",
      "epoch 137 loss: 2.9289\n",
      "epoch 138 loss: 6.6432\n",
      "epoch 139 loss: 2.1538\n",
      "epoch 140 loss: 6.1195\n",
      "epoch 141 loss: 4.8302\n",
      "epoch 142 loss: 3.8219\n",
      "epoch 143 loss: 3.4482\n",
      "epoch 144 loss: 3.6347\n",
      "epoch 145 loss: 4.2244\n",
      "epoch 146 loss: 8.5947\n",
      "epoch 147 loss: 7.0845\n",
      "epoch 148 loss: 6.4544\n",
      "epoch 149 loss: 0.9004\n",
      "epoch 150 loss: 2.8424\n",
      "epoch 151 loss: 8.3265\n",
      "epoch 152 loss: 3.9252\n",
      "epoch 153 loss: 4.5110\n",
      "epoch 154 loss: 1.0964\n",
      "epoch 155 loss: 4.2012\n",
      "epoch 156 loss: 1.7539\n",
      "epoch 157 loss: 4.7848\n",
      "epoch 158 loss: 5.5694\n",
      "epoch 159 loss: 1.2978\n",
      "epoch 160 loss: 31.4497\n",
      "epoch 161 loss: 8.3821\n",
      "epoch 162 loss: 4.7434\n",
      "epoch 163 loss: 6.0265\n",
      "epoch 164 loss: 21.7572\n",
      "epoch 165 loss: 5.9373\n",
      "epoch 166 loss: 2.4961\n",
      "epoch 167 loss: 8.5973\n",
      "epoch 168 loss: 6.4656\n",
      "epoch 169 loss: 1.9080\n",
      "epoch 170 loss: 0.9541\n",
      "epoch 171 loss: 1.6306\n",
      "epoch 172 loss: 9.3107\n",
      "epoch 173 loss: 9.2966\n",
      "epoch 174 loss: 1.1622\n",
      "epoch 175 loss: 5.8266\n",
      "epoch 176 loss: 4.5214\n",
      "epoch 177 loss: 4.5016\n",
      "epoch 178 loss: 1.7527\n",
      "epoch 179 loss: 1.8104\n",
      "epoch 180 loss: 1.4525\n",
      "epoch 181 loss: 2.1015\n",
      "epoch 182 loss: 2.1961\n",
      "epoch 183 loss: 3.3484\n",
      "epoch 184 loss: 1.7356\n",
      "epoch 185 loss: 6.9198\n",
      "epoch 186 loss: 0.8545\n",
      "epoch 187 loss: 4.1775\n",
      "epoch 188 loss: 7.5387\n",
      "epoch 189 loss: 5.7649\n",
      "epoch 190 loss: 6.2774\n",
      "epoch 191 loss: 3.3209\n",
      "epoch 192 loss: 14.3509\n",
      "epoch 193 loss: 5.8642\n",
      "epoch 194 loss: 9.0317\n",
      "epoch 195 loss: 4.3080\n",
      "epoch 196 loss: 9.5139\n",
      "epoch 197 loss: 3.3292\n",
      "epoch 198 loss: 3.2844\n",
      "epoch 199 loss: 1.6561\n",
      "epoch 200 loss: 5.0842\n",
      "epoch 201 loss: 11.7215\n",
      "epoch 202 loss: 1.5274\n",
      "epoch 203 loss: 4.8528\n",
      "epoch 204 loss: 1.9253\n",
      "epoch 205 loss: 3.6772\n",
      "epoch 206 loss: 3.7983\n",
      "epoch 207 loss: 9.0898\n",
      "epoch 208 loss: 7.9501\n",
      "epoch 209 loss: 1.8992\n",
      "epoch 210 loss: 1.6741\n",
      "epoch 211 loss: 3.1793\n",
      "epoch 212 loss: 0.9238\n",
      "epoch 213 loss: 6.2221\n",
      "epoch 214 loss: 1.3817\n",
      "epoch 215 loss: 2.3046\n",
      "epoch 216 loss: 7.5877\n",
      "epoch 217 loss: 1.3141\n",
      "epoch 218 loss: 10.8422\n",
      "epoch 219 loss: 6.2117\n",
      "epoch 220 loss: 4.5639\n",
      "epoch 221 loss: 2.8826\n",
      "epoch 222 loss: 4.3510\n",
      "epoch 223 loss: 1.8129\n",
      "epoch 224 loss: 10.4324\n",
      "epoch 225 loss: 1.3643\n",
      "epoch 226 loss: 5.0233\n",
      "epoch 227 loss: 4.8150\n",
      "epoch 228 loss: 1.4965\n",
      "epoch 229 loss: 0.6749\n",
      "epoch 230 loss: 11.0659\n",
      "epoch 231 loss: 2.5542\n",
      "epoch 232 loss: 3.8911\n",
      "epoch 233 loss: 1.7789\n",
      "epoch 234 loss: 9.5755\n",
      "epoch 235 loss: 3.9711\n",
      "epoch 236 loss: 1.4783\n",
      "epoch 237 loss: 7.3165\n",
      "epoch 238 loss: 6.8192\n",
      "epoch 239 loss: 2.4890\n",
      "epoch 240 loss: 3.7490\n",
      "epoch 241 loss: 4.5240\n",
      "epoch 242 loss: 7.4938\n",
      "epoch 243 loss: 7.4529\n",
      "epoch 244 loss: 3.5612\n",
      "epoch 245 loss: 7.0240\n",
      "epoch 246 loss: 5.0688\n",
      "epoch 247 loss: 1.1203\n",
      "epoch 248 loss: 4.4058\n",
      "epoch 249 loss: 1.0279\n",
      "epoch 250 loss: 23.4249\n",
      "epoch 251 loss: 0.3395\n",
      "epoch 252 loss: 1.1521\n",
      "epoch 253 loss: 9.9348\n",
      "epoch 254 loss: 1.8902\n",
      "epoch 255 loss: 0.9887\n",
      "epoch 256 loss: 4.3702\n",
      "epoch 257 loss: 24.8090\n",
      "epoch 258 loss: 0.8922\n",
      "epoch 259 loss: 1.8978\n",
      "epoch 260 loss: 0.4158\n",
      "epoch 261 loss: 6.9102\n",
      "epoch 262 loss: 10.5375\n",
      "epoch 263 loss: 11.1775\n",
      "epoch 264 loss: 7.3189\n",
      "epoch 265 loss: 1.9977\n",
      "epoch 266 loss: 3.8565\n",
      "epoch 267 loss: 0.8551\n",
      "epoch 268 loss: 1.3499\n",
      "epoch 269 loss: 9.0313\n",
      "epoch 270 loss: 7.3772\n",
      "epoch 271 loss: 1.7783\n",
      "epoch 272 loss: 2.3957\n",
      "epoch 273 loss: 2.6136\n",
      "epoch 274 loss: 2.4968\n",
      "epoch 275 loss: 4.2642\n",
      "epoch 276 loss: 24.0867\n",
      "epoch 277 loss: 1.4646\n",
      "epoch 278 loss: 0.6822\n",
      "epoch 279 loss: 4.3856\n",
      "epoch 280 loss: 5.4629\n",
      "epoch 281 loss: 1.2912\n",
      "epoch 282 loss: 2.7028\n",
      "epoch 283 loss: 2.0902\n",
      "epoch 284 loss: 5.2640\n",
      "epoch 285 loss: 9.5063\n",
      "epoch 286 loss: 8.2946\n",
      "epoch 287 loss: 1.2387\n",
      "epoch 288 loss: 2.8049\n",
      "epoch 289 loss: 2.0339\n",
      "epoch 290 loss: 5.2741\n",
      "epoch 291 loss: 1.8655\n",
      "epoch 292 loss: 2.8877\n",
      "epoch 293 loss: 3.5907\n",
      "epoch 294 loss: 3.8942\n",
      "epoch 295 loss: 2.0842\n",
      "epoch 296 loss: 2.8266\n",
      "epoch 297 loss: 6.6097\n",
      "epoch 298 loss: 1.9343\n",
      "epoch 299 loss: 0.2720\n",
      "epoch 300 loss: 5.2894\n",
      "epoch 301 loss: 5.1170\n",
      "epoch 302 loss: 2.5737\n",
      "epoch 303 loss: 9.2706\n",
      "epoch 304 loss: 2.4685\n",
      "epoch 305 loss: 11.1802\n",
      "epoch 306 loss: 11.4401\n",
      "epoch 307 loss: 1.6105\n",
      "epoch 308 loss: 0.6480\n",
      "epoch 309 loss: 0.9868\n",
      "epoch 310 loss: 3.2796\n",
      "epoch 311 loss: 1.8953\n",
      "epoch 312 loss: 1.0416\n",
      "epoch 313 loss: 1.6661\n",
      "epoch 314 loss: 2.4266\n",
      "epoch 315 loss: 7.4198\n",
      "epoch 316 loss: 7.7581\n",
      "epoch 317 loss: 9.1247\n",
      "epoch 318 loss: 0.5247\n",
      "epoch 319 loss: 3.7164\n",
      "epoch 320 loss: 2.0447\n",
      "epoch 321 loss: 1.1106\n",
      "epoch 322 loss: 26.8858\n",
      "epoch 323 loss: 3.8237\n",
      "epoch 324 loss: 2.8524\n",
      "epoch 325 loss: 3.5224\n",
      "epoch 326 loss: 9.5706\n",
      "epoch 327 loss: 0.9181\n",
      "epoch 328 loss: 2.7881\n",
      "epoch 329 loss: 4.5223\n",
      "epoch 330 loss: 3.6702\n",
      "epoch 331 loss: 1.0209\n",
      "epoch 332 loss: 8.0085\n",
      "epoch 333 loss: 6.7392\n",
      "epoch 334 loss: 2.0343\n",
      "epoch 335 loss: 1.7355\n",
      "epoch 336 loss: 1.2802\n",
      "epoch 337 loss: 4.2478\n",
      "epoch 338 loss: 6.0463\n",
      "epoch 339 loss: 2.9332\n",
      "epoch 340 loss: 11.6820\n",
      "epoch 341 loss: 0.8063\n",
      "epoch 342 loss: 8.0460\n",
      "epoch 343 loss: 5.9423\n",
      "epoch 344 loss: 5.1531\n",
      "epoch 345 loss: 2.6710\n",
      "epoch 346 loss: 0.4369\n",
      "epoch 347 loss: 1.2066\n",
      "epoch 348 loss: 1.3279\n",
      "epoch 349 loss: 12.2347\n",
      "epoch 350 loss: 2.0802\n",
      "epoch 351 loss: 4.6784\n",
      "epoch 352 loss: 5.6618\n",
      "epoch 353 loss: 2.7271\n",
      "epoch 354 loss: 3.1093\n",
      "epoch 355 loss: 5.3732\n",
      "epoch 356 loss: 5.2470\n",
      "epoch 357 loss: 2.0785\n",
      "epoch 358 loss: 2.7247\n",
      "epoch 359 loss: 4.4460\n",
      "epoch 360 loss: 3.5643\n",
      "epoch 361 loss: 6.4320\n",
      "epoch 362 loss: 3.3606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 363 loss: 2.1106\n",
      "epoch 364 loss: 1.8815\n",
      "epoch 365 loss: 1.3220\n",
      "epoch 366 loss: 3.0568\n",
      "epoch 367 loss: 8.0411\n",
      "epoch 368 loss: 1.7386\n",
      "epoch 369 loss: 3.4121\n",
      "epoch 370 loss: 7.3996\n",
      "epoch 371 loss: 5.0999\n",
      "epoch 372 loss: 6.6351\n",
      "epoch 373 loss: 31.5397\n",
      "epoch 374 loss: 1.2956\n",
      "epoch 375 loss: 28.8946\n",
      "epoch 376 loss: 2.5937\n",
      "epoch 377 loss: 2.4932\n",
      "epoch 378 loss: 4.9650\n",
      "epoch 379 loss: 1.7083\n",
      "epoch 380 loss: 9.1604\n",
      "epoch 381 loss: 1.2923\n",
      "epoch 382 loss: 3.8464\n",
      "epoch 383 loss: 0.9335\n",
      "epoch 384 loss: 2.5099\n",
      "epoch 385 loss: 3.3430\n",
      "epoch 386 loss: 11.1192\n",
      "epoch 387 loss: 2.8114\n",
      "epoch 388 loss: 9.3178\n",
      "epoch 389 loss: 2.0268\n",
      "epoch 390 loss: 3.2545\n",
      "epoch 391 loss: 3.5246\n",
      "epoch 392 loss: 1.1590\n",
      "epoch 393 loss: 3.8532\n",
      "epoch 394 loss: 5.8092\n",
      "epoch 395 loss: 4.8449\n",
      "epoch 396 loss: 3.6519\n",
      "epoch 397 loss: 2.0389\n",
      "epoch 398 loss: 0.8699\n",
      "epoch 399 loss: 2.6291\n",
      "epoch 400 loss: 0.7349\n",
      "epoch 401 loss: 3.8115\n",
      "epoch 402 loss: 1.7947\n",
      "epoch 403 loss: 2.6131\n",
      "epoch 404 loss: 2.0905\n",
      "epoch 405 loss: 8.3378\n",
      "epoch 406 loss: 2.3345\n",
      "epoch 407 loss: 9.9773\n",
      "epoch 408 loss: 1.8541\n",
      "epoch 409 loss: 2.9407\n",
      "epoch 410 loss: 3.4758\n",
      "epoch 411 loss: 1.2073\n",
      "epoch 412 loss: 4.2694\n",
      "epoch 413 loss: 5.2306\n",
      "epoch 414 loss: 2.9019\n",
      "epoch 415 loss: 24.7346\n",
      "epoch 416 loss: 2.4364\n",
      "epoch 417 loss: 2.9679\n",
      "epoch 418 loss: 2.7901\n",
      "epoch 419 loss: 2.0365\n",
      "epoch 420 loss: 2.5784\n",
      "epoch 421 loss: 12.9183\n",
      "epoch 422 loss: 3.1924\n",
      "epoch 423 loss: 3.1293\n",
      "epoch 424 loss: 4.4008\n",
      "epoch 425 loss: 0.8784\n",
      "epoch 426 loss: 3.4563\n",
      "epoch 427 loss: 1.3012\n",
      "epoch 428 loss: 1.5813\n",
      "epoch 429 loss: 1.3188\n",
      "epoch 430 loss: 7.8150\n",
      "epoch 431 loss: 1.1234\n",
      "epoch 432 loss: 5.2210\n",
      "epoch 433 loss: 1.0096\n",
      "epoch 434 loss: 1.1399\n",
      "epoch 435 loss: 0.9161\n",
      "epoch 436 loss: 1.3744\n",
      "epoch 437 loss: 5.5339\n",
      "epoch 438 loss: 1.0164\n",
      "epoch 439 loss: 1.8264\n",
      "epoch 440 loss: 5.6022\n",
      "epoch 441 loss: 2.9871\n",
      "epoch 442 loss: 8.8052\n",
      "epoch 443 loss: 2.9054\n",
      "epoch 444 loss: 6.3069\n",
      "epoch 445 loss: 0.8834\n",
      "epoch 446 loss: 2.1860\n",
      "epoch 447 loss: 1.9472\n",
      "epoch 448 loss: 1.1140\n",
      "epoch 449 loss: 3.0523\n",
      "epoch 450 loss: 1.9918\n",
      "epoch 451 loss: 8.6122\n",
      "epoch 452 loss: 2.3269\n",
      "epoch 453 loss: 4.2597\n",
      "epoch 454 loss: 4.3193\n",
      "epoch 455 loss: 3.0925\n",
      "epoch 456 loss: 1.4714\n",
      "epoch 457 loss: 1.4341\n",
      "epoch 458 loss: 4.6581\n",
      "epoch 459 loss: 1.1011\n",
      "epoch 460 loss: 2.9620\n",
      "epoch 461 loss: 2.9248\n",
      "epoch 462 loss: 4.8644\n",
      "epoch 463 loss: 2.3016\n",
      "epoch 464 loss: 3.2603\n",
      "epoch 465 loss: 1.9837\n",
      "epoch 466 loss: 1.4433\n",
      "epoch 467 loss: 7.5340\n",
      "epoch 468 loss: 0.9282\n",
      "epoch 469 loss: 1.7470\n",
      "epoch 470 loss: 5.6029\n",
      "epoch 471 loss: 4.0986\n",
      "epoch 472 loss: 1.9610\n",
      "epoch 473 loss: 2.7924\n",
      "epoch 474 loss: 2.8665\n",
      "epoch 475 loss: 15.2708\n",
      "epoch 476 loss: 2.5740\n",
      "epoch 477 loss: 2.8820\n",
      "epoch 478 loss: 2.8366\n",
      "epoch 479 loss: 1.3613\n",
      "epoch 480 loss: 1.2650\n",
      "epoch 481 loss: 2.1698\n",
      "epoch 482 loss: 1.2992\n",
      "epoch 483 loss: 1.3197\n",
      "epoch 484 loss: 9.9543\n",
      "epoch 485 loss: 0.8874\n",
      "epoch 486 loss: 3.8575\n",
      "epoch 487 loss: 0.8471\n",
      "epoch 488 loss: 5.2273\n",
      "epoch 489 loss: 3.4692\n",
      "epoch 490 loss: 1.0102\n",
      "epoch 491 loss: 2.8317\n",
      "epoch 492 loss: 4.0200\n",
      "epoch 493 loss: 2.8056\n",
      "epoch 494 loss: 6.4268\n",
      "epoch 495 loss: 8.3419\n",
      "epoch 496 loss: 4.6298\n",
      "epoch 497 loss: 1.3395\n",
      "epoch 498 loss: 3.7609\n",
      "epoch 499 loss: 1.0177\n",
      "epoch 500 loss: 1.7416\n"
     ]
    }
   ],
   "source": [
    "Loss = []\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch {} loss: {:.4f}\".format(epoch + 1, loss.item()))\n",
    "    Loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test_ts.to(device)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $r^2$ 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8590828719379164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f597377c70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_test[:, 0], y_test, c='b', label=\"true\")\n",
    "plt.scatter(X_test[:, 0], y_pred, c='r', label=\"prediction\")\n",
    "plt.xlabel('cylinders')\n",
    "plt.ylabel('mpg')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
